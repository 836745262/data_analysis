{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscriberID</th>\n",
       "      <th>churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>AGE</th>\n",
       "      <th>edu_class</th>\n",
       "      <th>incomeCode</th>\n",
       "      <th>duration</th>\n",
       "      <th>feton</th>\n",
       "      <th>peakMinAv</th>\n",
       "      <th>peakMinDiff</th>\n",
       "      <th>posTrend</th>\n",
       "      <th>negTrend</th>\n",
       "      <th>nrProm</th>\n",
       "      <th>prom</th>\n",
       "      <th>curPlan</th>\n",
       "      <th>avgplan</th>\n",
       "      <th>planChange</th>\n",
       "      <th>posPlanChange</th>\n",
       "      <th>negPlanChange</th>\n",
       "      <th>call_10086</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19164958.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.666667</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39244924.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>-371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39578413.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>-784.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40992265.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43061957.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.333333</td>\n",
       "      <td>-334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subscriberID  churn  gender   AGE  edu_class  incomeCode  duration  feton  \\\n",
       "0    19164958.0    1.0     0.0  20.0        2.0        12.0      16.0    0.0   \n",
       "1    39244924.0    1.0     1.0  20.0        0.0        21.0       5.0    0.0   \n",
       "2    39578413.0    1.0     0.0  11.0        1.0        47.0       3.0    0.0   \n",
       "3    40992265.0    1.0     0.0  43.0        0.0         4.0      12.0    0.0   \n",
       "4    43061957.0    1.0     1.0  60.0        0.0         9.0      14.0    0.0   \n",
       "\n",
       "    peakMinAv  peakMinDiff  posTrend  negTrend  nrProm  prom  curPlan  \\\n",
       "0  113.666667         -8.0       0.0       1.0     0.0   0.0      1.0   \n",
       "1  274.000000       -371.0       0.0       1.0     2.0   1.0      3.0   \n",
       "2  392.000000       -784.0       0.0       1.0     0.0   0.0      3.0   \n",
       "3   31.000000        -76.0       0.0       1.0     2.0   1.0      3.0   \n",
       "4  129.333333       -334.0       0.0       1.0     0.0   0.0      3.0   \n",
       "\n",
       "   avgplan  planChange  posPlanChange  negPlanChange  call_10086  \n",
       "0      1.0         0.0            0.0            0.0         0.0  \n",
       "1      2.0         2.0            1.0            0.0         1.0  \n",
       "2      3.0         0.0            0.0            0.0         1.0  \n",
       "3      3.0         0.0            0.0            0.0         1.0  \n",
       "4      3.0         0.0            0.0            0.0         0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pd.read_csv('C:/Users/acerpc/Desktop/data_folder/telecom_churn.csv')\n",
    "churn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = churn.loc[:,'gender':]\n",
    "y = churn['churn']\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_x_train = scaler.fit_transform(train_x)\n",
    "scaler_x_test = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=10, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,50),solver='sgd',max_iter=10,learning_rate_init=0.1,random_state=1)\n",
    "mlp.fit(scaler_x_train,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = mlp.predict(scaler_x_train)\n",
    "predict_test = mlp.predict(scaler_x_test)\n",
    "proba_train = mlp.predict_proba(scaler_x_train)[:,1]\n",
    "proba_test = mlp.predict_proba(scaler_x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_test.shape\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154222489838928\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.roc_auc_score(test_y,proba_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.98      0.81       584\n",
      "         1.0       0.94      0.43      0.59       455\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1039\n",
      "   macro avg       0.82      0.71      0.70      1039\n",
      "weighted avg       0.80      0.74      0.71      1039\n",
      "\n",
      "[[572  12]\n",
      " [258 197]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_y,predict_test))\n",
    "print(metrics.confusion_matrix(test_y,predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7401347449470644"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(scaler_x_test,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-bd5d1590efdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmlp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m param_grid = {'hidden_layer_sizes':[(i,j) for i in range(101) for j in range(101)],'max_iter':list(range(10,1010,10)),\n\u001b[1;32m----> 5\u001b[1;33m               'learning_rate_init':list(range(0.001,0.1,0.001))}\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp1 = MLPClassifier(solver='sgd')\n",
    "param_grid = {'hidden_layer_sizes':[(i,j) for i in range(101) for j in range(101)],'max_iter':list(range(10,1010,10)),\n",
    "              'learning_rate_init':list(np.arrange(0.001,0.1,0.001))}\n",
    "cv = GridSearchCV(mlp1,param_grid,scoring='roc_auc',cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hidden_layer_sizes :元祖格式，长度=n_layers-2, 默认(100，），第i个元素表示第i个隐藏层的神经元的个数。 \n",
    "2. activation :{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, 默认‘relu \n",
    "- ‘identity’： no-op activation, useful to implement linear bottleneck， \n",
    "返回f(x) = x \n",
    "- ‘logistic’：the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)). \n",
    "- ‘tanh’：the hyperbolic tan function, returns f(x) = tanh(x). \n",
    "- ‘relu’：the rectified linear unit function, returns f(x) = max(0, x) \n",
    "4. solver： {‘lbfgs’, ‘sgd’, ‘adam’}, 默认 ‘adam’，用来优化权重 \n",
    "- lbfgs：quasi-Newton方法的优化器 \n",
    "- sgd：随机梯度下降 \n",
    "- adam： Kingma, Diederik, and Jimmy Ba提出的机遇随机梯度的优化器 \n",
    "注意：默认solver ‘adam’在相对较大的数据集上效果比较好（几千个样本或者更多），对小数据集来说，lbfgs收敛更快效果也更好。 \n",
    "5. alpha :float,可选的，默认0.0001,正则化项参数 \n",
    "6. batch_size : int , 可选的，默认‘auto’,随机优化的minibatches的大小，如果solver是‘lbfgs’，分类器将不使用minibatch，当设置成‘auto’，batch_size=min(200,n_samples) \n",
    "7. learning_rate :{‘constant’，‘invscaling’, ‘adaptive’},默认‘constant’，用于权重更新，只有当solver为’sgd‘时使用 \n",
    "- ‘constant’: 有‘learning_rate_init’给定的恒定学习率 \n",
    "- ‘incscaling’：随着时间t使用’power_t’的逆标度指数不断降低学习率learning_rate_ ，effective_learning_rate = learning_rate_init / pow(t, power_t) \n",
    "- ‘adaptive’：只要训练损耗在下降，就保持学习率为’learning_rate_init’不变，当连续两次不能降低训练损耗或验证分数停止升高至少tol时，将当前学习率除以5. \n",
    "8. max_iter: int，可选，默认200，最大迭代次数。 \n",
    "9. random_state:int 或RandomState，可选，默认None，随机数生成器的状态或种子。 \n",
    "10. shuffle: bool，可选，默认True,只有当solver=’sgd’或者‘adam’时使用，判断是否在每次迭代时对样本进行清洗。 \n",
    "11. tol：float, 可选，默认1e-4，优化的容忍度 \n",
    "12. learning_rate_int:double,可选，默认0.001，初始学习率，控制更新权重的补偿，只有当solver=’sgd’ 或’adam’时使用。 \n",
    "13. power_t: double, optional, default 0.5，只有solver=’sgd’时使用，是逆扩展学习率的指数.当learning_rate=’invscaling’，用来更新有效学习率。 \n",
    "14. verbose : bool, optional, default False,是否将过程打印到stdout \n",
    "15. warm_start : bool, optional, default False,当设置成True，使用之前的解决方法作为初始拟合，否则释放之前的解决方法。 \n",
    "16. momentum : float, default 0.9,Momentum(动量） for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’. \n",
    "17. nesterovs_momentum : boolean, default True, Whether to use Nesterov’s momentum. Only used when solver=’sgd’ and momentum > 0. \n",
    "18. early_stopping : bool, default False,Only effective when solver=’sgd’ or ‘adam’,判断当验证效果不再改善的时候是否终止训练，当为True时，自动选出10%的训练数据用于验证并在两步连续爹迭代改善低于tol时终止训练。 \n",
    "19. validation_fraction : float, optional, default 0.1,用作早期停止验证的预留训练数据集的比例，早0-1之间，只当early_stopping=True有用 \n",
    "20. beta_1 : float, optional, default 0.9，Only used when solver=’adam’，估计一阶矩向量的指数衰减速率，[0,1)之间 \n",
    "21. beta_2 : float, optional, default 0.999,Only used when solver=’adam’估计二阶矩向量的指数衰减速率[0,1)之间 \n",
    "22. epsilon : float, optional, default 1e-8,Only used when solver=’adam’数值稳定值。 \n",
    "属性说明： \n",
    "- classes_:每个输出的类标签 \n",
    "- loss_:损失函数计算出来的当前损失值 \n",
    "- coefs_:列表中的第i个元素表示i层的权重矩阵 \n",
    "- intercepts_:列表中第i个元素代表i+1层的偏差向量 \n",
    "- n_iter_ ：迭代次数 \n",
    "- n_layers_:层数 \n",
    "- n_outputs_:输出的个数 \n",
    "- out_activation_:输出激活函数的名称。 \n",
    "方法说明： \n",
    "- fit(X,y):拟合 \n",
    "- get_params([deep]):获取参数 \n",
    "- predict(X):使用MLP进行预测 \n",
    "- predic_log_proba(X):返回对数概率估计 \n",
    "- predic_proba(X)：概率估计 \n",
    "- score(X,y[,sample_weight]):返回给定测试数据和标签上的平均准确度 \n",
    "-set_params(**params):设置参数。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
